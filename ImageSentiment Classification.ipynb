{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b1b627-0800-4ab3-a06a-567654a70c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89e4b2d-41e3-4066-8b7e-8a9eef467ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead95f24-c13a-4265-aae0-f3bdb95c4046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51676, 1, 48, 48]) torch.Size([2871, 1, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "# Geting training/validating dataset\n",
    "x_train = []\n",
    "x_label = []\n",
    "val_train = []\n",
    "val_label = []\n",
    "raw_train = np.genfromtxt('train.csv', delimiter=',', dtype=str, skip_header=1)\n",
    "for i in range(len(raw_train)):\n",
    "    image = np.array(raw_train[i, 1].split(' ')).reshape(1, 48, 48)\n",
    "    if (i % 10 == 0):\n",
    "        val_train.append(image)\n",
    "        val_label.append(raw_train[i][0])\n",
    "    else:\n",
    "        x_train.append(image)\n",
    "        x_train.append(np.flip(image, axis=2))    # simple example of data augmentation\n",
    "        x_label.append(raw_train[i][0])\n",
    "        x_label.append(raw_train[i][0])\n",
    "x_train = np.array(x_train, dtype=float) / 255.0\n",
    "val_train = np.array(val_train, dtype=float) / 255.0\n",
    "x_label = np.array(x_label, dtype=int)\n",
    "val_label = np.array(val_label, dtype=int)\n",
    "\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "val_train = torch.FloatTensor(val_train)\n",
    "x_label = torch.LongTensor(x_label)\n",
    "val_label = torch.LongTensor(val_label)\n",
    "print(x_train.size(), val_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5452c309-df2e-44d0-bca8-03db591072f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrapped as dataloaders\n",
    "train_set = TensorDataset(x_train, x_label)\n",
    "val_set = TensorDataset(val_train, val_label)\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a590b83-eeb6-4f7c-a1e1-f15384b09525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaussian_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 and classname.find('Conv') == 0:\n",
    "        m.weight.data.normal_(0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f933d7c0-b0be-4df9-b165-dc7d0dd2d2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1),  # [64, 24, 24]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 12, 12]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 6, 6]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2, 0)       # [256, 3, 3]\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*3*3, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 7)\n",
    "        )\n",
    "\n",
    "        self.cnn.apply(gaussian_weights_init)\n",
    "        self.fc.apply(gaussian_weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effba37e-3dac-47a2-a100-9de36c8d6e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.2)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): LeakyReLU(negative_slope=0.2)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): LeakyReLU(negative_slope=0.2)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): LeakyReLU(negative_slope=0.2)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2304, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Classifier().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4147e6b7-6b50-4e2a-b733-b2f3411488cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "best_acc = 0.0\n",
    "num_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "159baa0c-907c-4853-8ba7-4a04eb44da8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/030] 52.48 sec(s) Train Acc: 0.213774 Loss: 903.151809 | Val Acc: 0.269244 loss: 21.671302\n",
      "Model Saved!\n",
      "[002/030] 38.90 sec(s) Train Acc: 0.250774 Loss: 369.241852 | Val Acc: 0.284570 loss: 21.136398\n",
      "Model Saved!\n",
      "[003/030] 27.23 sec(s) Train Acc: 0.278427 Loss: 359.111871 | Val Acc: 0.308255 loss: 20.620061\n",
      "Model Saved!\n",
      "[004/030] 27.21 sec(s) Train Acc: 0.337778 Loss: 338.321874 | Val Acc: 0.370951 loss: 18.922485\n",
      "Model Saved!\n",
      "[005/030] 27.64 sec(s) Train Acc: 0.402044 Loss: 311.315560 | Val Acc: 0.428770 loss: 17.290852\n",
      "Model Saved!\n",
      "[006/030] 27.89 sec(s) Train Acc: 0.449319 Loss: 288.798981 | Val Acc: 0.386973 loss: 18.818995\n",
      "[007/030] 27.73 sec(s) Train Acc: 0.485680 Loss: 270.866411 | Val Acc: 0.499478 loss: 15.856680\n",
      "Model Saved!\n",
      "[008/030] 27.57 sec(s) Train Acc: 0.520590 Loss: 255.472964 | Val Acc: 0.529432 loss: 14.766501\n",
      "Model Saved!\n",
      "[009/030] 28.09 sec(s) Train Acc: 0.542167 Loss: 243.480652 | Val Acc: 0.516545 loss: 15.190772\n",
      "[010/030] 26.91 sec(s) Train Acc: 0.562814 Loss: 231.961327 | Val Acc: 0.557297 loss: 13.873153\n",
      "Model Saved!\n",
      "[011/030] 27.14 sec(s) Train Acc: 0.579786 Loss: 223.589833 | Val Acc: 0.521421 loss: 15.412722\n",
      "[012/030] 28.30 sec(s) Train Acc: 0.598866 Loss: 213.381498 | Val Acc: 0.587252 loss: 13.286596\n",
      "Model Saved!\n",
      "[013/030] 29.16 sec(s) Train Acc: 0.617076 Loss: 205.444685 | Val Acc: 0.579241 loss: 13.287960\n",
      "[014/030] 28.48 sec(s) Train Acc: 0.630544 Loss: 197.475154 | Val Acc: 0.567746 loss: 14.273817\n",
      "[015/030] 27.62 sec(s) Train Acc: 0.640007 Loss: 191.616565 | Val Acc: 0.585510 loss: 13.480974\n",
      "[016/030] 27.49 sec(s) Train Acc: 0.651773 Loss: 186.579734 | Val Acc: 0.588645 loss: 13.782398\n",
      "Model Saved!\n",
      "[017/030] 27.97 sec(s) Train Acc: 0.666673 Loss: 179.465538 | Val Acc: 0.598398 loss: 14.035588\n",
      "Model Saved!\n",
      "[018/030] 28.26 sec(s) Train Acc: 0.677162 Loss: 175.028842 | Val Acc: 0.573668 loss: 14.226254\n",
      "[019/030] 29.21 sec(s) Train Acc: 0.689585 Loss: 169.165734 | Val Acc: 0.591432 loss: 14.212408\n",
      "[020/030] 28.49 sec(s) Train Acc: 0.700441 Loss: 163.850290 | Val Acc: 0.582724 loss: 15.733314\n",
      "[021/030] 27.45 sec(s) Train Acc: 0.718012 Loss: 156.711661 | Val Acc: 0.583072 loss: 15.888643\n",
      "[022/030] 27.00 sec(s) Train Acc: 0.722095 Loss: 153.946253 | Val Acc: 0.581679 loss: 17.946105\n",
      "[023/030] 27.48 sec(s) Train Acc: 0.733184 Loss: 150.783787 | Val Acc: 0.569140 loss: 16.432258\n",
      "[024/030] 28.68 sec(s) Train Acc: 0.747910 Loss: 143.731181 | Val Acc: 0.570185 loss: 18.442630\n",
      "[025/030] 27.55 sec(s) Train Acc: 0.745472 Loss: 146.318203 | Val Acc: 0.573668 loss: 16.896451\n",
      "[026/030] 27.17 sec(s) Train Acc: 0.758089 Loss: 141.089804 | Val Acc: 0.521421 loss: 21.218159\n",
      "[027/030] 27.11 sec(s) Train Acc: 0.769080 Loss: 134.258228 | Val Acc: 0.599791 loss: 17.493873\n",
      "Model Saved!\n",
      "[028/030] 27.20 sec(s) Train Acc: 0.781136 Loss: 129.135918 | Val Acc: 0.580634 loss: 18.831156\n",
      "[029/030] 27.91 sec(s) Train Acc: 0.784000 Loss: 130.651096 | Val Acc: 0.584814 loss: 19.651725\n",
      "[030/030] 29.18 sec(s) Train Acc: 0.795050 Loss: 126.153633 | Val Acc: 0.552421 loss: 22.988691\n",
      "Finish Training!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        train_pred = model(data[0].to(device))\n",
    "        batch_loss = loss(train_pred, data[1].to(device))\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "        #Plot the progress\n",
    "        progress = ('#' * int(float(i)/len(train_loader)*40)).ljust(40)\n",
    "        print ('[%03d/%03d] %2.2f sec(s) | %s |' % (epoch+1, num_epoch, \\\n",
    "                (time.time() - epoch_start_time), progress), end='\\r', flush=True)\n",
    "        \n",
    "    model.eval()\n",
    "    for i, data in enumerate(val_loader):\n",
    "        val_pred = model(data[0].to(device))\n",
    "        batch_loss = loss(val_pred, data[1].to(device))\n",
    "\n",
    "        val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        val_loss += batch_loss.item()\n",
    "\n",
    "        progress = ('#' * int(float(i)/len(val_loader)*40)).ljust(40)\n",
    "        print ('[%03d/%03d] %2.2f sec(s) | %s |' % (epoch+1, num_epoch, \\\n",
    "                (time.time() - epoch_start_time), progress), end='\\r', flush=True)\n",
    "        \n",
    "    val_acc = val_acc/val_set.__len__()\n",
    "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "        (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "        train_acc/train_set.__len__(), train_loss, val_acc, val_loss))\n",
    "    \n",
    "    if (val_acc > best_acc):\n",
    "        with open('save/acc.txt','w') as f:\n",
    "            f.write(str(epoch)+'\\t'+str(val_acc)+'\\n')\n",
    "        torch.save(model.state_dict(), 'save/model.pth')\n",
    "        best_acc = val_acc\n",
    "        print ('Model Saved!')\n",
    "\n",
    "print(\"Finish Training!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d886e8ee-eada-4bed-8c1e-6010159eb784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7178, 1, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "raw_test = np.genfromtxt('test.csv', delimiter=',', dtype=str, skip_header=1)\n",
    "for i in range(len(raw_test)):\n",
    "    image = np.array(raw_test[i, 1].split(' ')).reshape(1, 48, 48)\n",
    "    x_test.append(image)\n",
    "x_test = np.array(x_test, dtype=float) / 255.0\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "print(x_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c09c6d0-dd19-413a-9583-3508a1ce2f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 6, 3,  ..., 3, 0, 2], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_pred = model(x_test.to(device))\n",
    "    value, indices = torch.max(test_pred, dim = 1)\n",
    "    print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "907a7c6b-b339-4487-b435-014d832b7b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = indices.cpu().numpy()\n",
    "\n",
    "df = pd.DataFrame({'id': range(len(indices)), 'label': indices})\n",
    "\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a64a89-5828-4ad8-a938-1dfa824cae24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
